{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b2ecdb-99a3-4619-8b3a-e96da14ae56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KANAK\\AppData\\Local\\Temp\\ipykernel_1728\\1928144932.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "D:\\anaconda\\envs\\tensorflow\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.49791 | test_accuracy: 0.35965 |  0:00:00s\n",
      "epoch 1  | loss: 1.73302 | test_accuracy: 0.3614  |  0:00:00s\n",
      "epoch 2  | loss: 1.32042 | test_accuracy: 0.47368 |  0:00:00s\n",
      "epoch 3  | loss: 1.04431 | test_accuracy: 0.54737 |  0:00:00s\n",
      "epoch 4  | loss: 0.84975 | test_accuracy: 0.59825 |  0:00:01s\n",
      "epoch 5  | loss: 0.71648 | test_accuracy: 0.72281 |  0:00:01s\n",
      "epoch 6  | loss: 0.64682 | test_accuracy: 0.75789 |  0:00:01s\n",
      "epoch 7  | loss: 0.5726  | test_accuracy: 0.75088 |  0:00:01s\n",
      "epoch 8  | loss: 0.549   | test_accuracy: 0.77368 |  0:00:01s\n",
      "epoch 9  | loss: 0.50645 | test_accuracy: 0.79298 |  0:00:02s\n",
      "epoch 10 | loss: 0.48586 | test_accuracy: 0.80175 |  0:00:02s\n",
      "epoch 11 | loss: 0.48688 | test_accuracy: 0.78772 |  0:00:02s\n",
      "epoch 12 | loss: 0.47916 | test_accuracy: 0.79123 |  0:00:02s\n",
      "epoch 13 | loss: 0.45473 | test_accuracy: 0.79123 |  0:00:02s\n",
      "epoch 14 | loss: 0.47113 | test_accuracy: 0.79825 |  0:00:03s\n",
      "epoch 15 | loss: 0.45203 | test_accuracy: 0.8     |  0:00:03s\n",
      "epoch 16 | loss: 0.45205 | test_accuracy: 0.80175 |  0:00:03s\n",
      "epoch 17 | loss: 0.45578 | test_accuracy: 0.79474 |  0:00:03s\n",
      "epoch 18 | loss: 0.42895 | test_accuracy: 0.8386  |  0:00:03s\n",
      "epoch 19 | loss: 0.42569 | test_accuracy: 0.79298 |  0:00:04s\n",
      "epoch 20 | loss: 0.42054 | test_accuracy: 0.80526 |  0:00:04s\n",
      "epoch 21 | loss: 0.38706 | test_accuracy: 0.80877 |  0:00:04s\n",
      "epoch 22 | loss: 0.4325  | test_accuracy: 0.80702 |  0:00:04s\n",
      "epoch 23 | loss: 0.43892 | test_accuracy: 0.79298 |  0:00:04s\n",
      "epoch 24 | loss: 0.41594 | test_accuracy: 0.81579 |  0:00:05s\n",
      "epoch 25 | loss: 0.40405 | test_accuracy: 0.82281 |  0:00:05s\n",
      "epoch 26 | loss: 0.4083  | test_accuracy: 0.80526 |  0:00:05s\n",
      "epoch 27 | loss: 0.37921 | test_accuracy: 0.81053 |  0:00:05s\n",
      "epoch 28 | loss: 0.3636  | test_accuracy: 0.87018 |  0:00:05s\n",
      "epoch 29 | loss: 0.3473  | test_accuracy: 0.79474 |  0:00:05s\n",
      "epoch 30 | loss: 0.3335  | test_accuracy: 0.83333 |  0:00:06s\n",
      "epoch 31 | loss: 0.32032 | test_accuracy: 0.8386  |  0:00:06s\n",
      "epoch 32 | loss: 0.3225  | test_accuracy: 0.80526 |  0:00:06s\n",
      "epoch 33 | loss: 0.32144 | test_accuracy: 0.83509 |  0:00:06s\n",
      "epoch 34 | loss: 0.33507 | test_accuracy: 0.79298 |  0:00:07s\n",
      "epoch 35 | loss: 0.33189 | test_accuracy: 0.81053 |  0:00:07s\n",
      "epoch 36 | loss: 0.30797 | test_accuracy: 0.85965 |  0:00:07s\n",
      "epoch 37 | loss: 0.3085  | test_accuracy: 0.83158 |  0:00:07s\n",
      "epoch 38 | loss: 0.29816 | test_accuracy: 0.86842 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_test_accuracy = 0.87018\n",
      "Test Accuracy: 87.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the CSV dataset\n",
    "data = pd.read_csv(r'C:\\Users\\KANAK\\Desktop\\Codes\\LoRaIoT\\GitHub/PHC_RawDataset.csv')\n",
    "\n",
    "# Assume the last column is the target variable\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values   # Target\n",
    "\n",
    "# Encode the target variable if it's categorical\n",
    "#label_encoder = LabelEncoder()\n",
    "#y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize TabNetClassifier\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "# Train the model (Fine-tuning)\n",
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_name=['test'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=200,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e9c0bf-b447-409d-95ec-0f2933dae8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "cm2 = pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318dd2f8-74ef-48e1-a4ab-77783784f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 98.94736842105263 100.0 81.25 89.65517241379311 0.8125 1.0 0.9013878188659973\n",
      "2 94.03508771929825 90.76923076923077 84.28571428571429 87.40740740740742 0.8428571428571429 0.9720930232558139 0.905171557315384\n",
      "3 97.89473684210527 92.80000000000001 97.47899159663865 95.08196721311477 0.9747899159663865 0.9800443458980045 0.9774136000594876\n",
      "4 94.38596491228071 86.48648648648648 84.95575221238938 85.71428571428571 0.8495575221238938 0.9671772428884027 0.9064616384176943\n",
      "5 98.24561403508771 91.01123595505618 97.59036144578313 94.18604651162791 0.9759036144578314 0.9835728952772074 0.979730750555366\n",
      "6 95.6140350877193 3.8461538461538463 100.0 7.407407407407408 1.0 0.9560632688927944 0.9777848786378291\n",
      "7 94.91228070175438 85.71428571428571 55.55555555555556 67.41573033707864 0.5555555555555556 0.9903100775193798 0.7417359808506961\n",
      "8 100.0 100.0 100.0 100.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(cm2.shape[0]):\n",
    "    TP = cm2.iloc[i,i]    # zeroth row & zeroth column\n",
    "    FP = cm2.iloc[i,:].sum()-TP \n",
    "    FN = cm2.iloc[:,i].sum()-TP\n",
    "    TN = cm2.sum().sum()-(TP+FP+FN)\n",
    "    Accuracy = ((TP+TN)/cm2.sum().sum()) *100\n",
    "    Precision = (TP/(TP+FP)) * 100\n",
    "    Recall = (TP/(TP+FN)) * 100\n",
    "    F1_Score = (2 * Precision * Recall)/(Precision + Recall)\n",
    "    Sensitivity = (TP/(TP+FN))\n",
    "    Specificity = (TN/(FP+TN))\n",
    "    G_Mean = math.sqrt((TP/(TP+FN))*(TN/(FP+TN)))\n",
    "    print(cm2.index[i], Accuracy,  Precision,  Recall,  F1_Score, Sensitivity, Specificity, G_Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54b589-0770-48ba-bba1-94f9c87abbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
